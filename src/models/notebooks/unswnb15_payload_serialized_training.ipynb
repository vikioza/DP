{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikio\\AppData\\Local\\Temp\\ipykernel_31752\\2052541112.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "# Input params\n",
    "HEIGHT = 64\n",
    "WIDTH = 128\n",
    "IN_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Embedding params\n",
    "PATCH_SIZE = 16\n",
    "EMBED_DIM = (PATCH_SIZE ** 2) * IN_CHANNELS\n",
    "NUM_PATCHES = (HEIGHT // PATCH_SIZE) * (WIDTH // PATCH_SIZE)\n",
    "DROPOUT = 0.01\n",
    "\n",
    "# Model params\n",
    "NUM_HEADS = 12\n",
    "NUM_ENCODERS = 12\n",
    "ACTIVATION=\"gelu\"\n",
    "\n",
    "# Optim params\n",
    "ADAM_BETAS = (0.9, 0.999)\n",
    "ADAM_WEIGHT_DECAY = 0\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Train loop params\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, patch_size, num_patches, dropout, in_channels):\n",
    "        super().__init__()\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "            ),\n",
    "            nn.Flatten(2))\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(size=(1, in_channels, embed_dim)), requires_grad=True)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(size=(1, num_patches+in_channels, embed_dim)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "\n",
    "        x = self.patcher(x).permute(0, 2, 1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        x = self.position_embeddings + x\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 35, 768])\n"
     ]
    }
   ],
   "source": [
    "model = PatchEmbedding(EMBED_DIM, PATCH_SIZE, NUM_PATCHES, DROPOUT, IN_CHANNELS).to(device)\n",
    "x = torch.randn(BATCH_SIZE, IN_CHANNELS, HEIGHT, WIDTH).to(device)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_patches, num_classes, patch_size, embed_dim, num_encoders, num_heads, dropout, activation, in_channels):\n",
    "        super().__init__()\n",
    "        self.embeddings_block = PatchEmbedding(embed_dim, patch_size, num_patches, dropout, in_channels)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True)\n",
    "        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim),\n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings_block(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.mlp_head(x[:, 0, :])  # Apply MLP on the CLS token only\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "model = ViT(NUM_PATCHES, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, DROPOUT, ACTIVATION, IN_CHANNELS).to(device)\n",
    "x = torch.randn(BATCH_SIZE, IN_CHANNELS, HEIGHT, WIDTH).to(device)\n",
    "print(model(x).shape) # BATCH_SIZE X NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (embeddings_block): PatchEmbedding(\n",
       "    (patcher): Sequential(\n",
       "      (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (1): Flatten(start_dim=2, end_dim=-1)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.01, inplace=False)\n",
       "  )\n",
       "  (encoder_blocks): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.01, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.01, inplace=False)\n",
       "        (dropout2): Dropout(p=0.01, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=768, out_features=10, bias=True)\n",
       "    (2): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNSW_NB15(Dataset):\n",
    "    BASE_PATH = \"C:\\VScode Projects\\FIIT_MASTERS\\DP\\datasets\\\\UNSW_NB15\"\n",
    "    MAPPING_FILE = \"\\\\unswnb15_img_serialized_5_non_shuffled.csv\"\n",
    "    FOLDER = \"\\image_serialized_5_non_shuffled\"\n",
    "    index: int\n",
    "    batch_size: int\n",
    "    classes_count: int\n",
    "    classes_list: list\n",
    "    \n",
    "    def __init__(self, shuffle: bool = False):        \n",
    "        self.mapping = pd.read_csv(self.BASE_PATH+self.MAPPING_FILE)\n",
    "        self.mapping = pd.get_dummies(self.mapping, columns=['label'])\n",
    "        \n",
    "        if shuffle:\n",
    "            self.mapping = self.mapping.sample(frac=1) # shuffle\n",
    "            \n",
    "        self.classes_list = [label.split(\"_\")[1] for label in self.mapping.columns[1:]]\n",
    "        \n",
    "        self.mapping = self.mapping.to_numpy()\n",
    "        \n",
    "        self.classes_count = len(self.mapping[0]) - 1\n",
    "        \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()]) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mapping)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.mapping[idx, 0]\n",
    "        img_path = os.path.join(self.BASE_PATH + self.FOLDER, img_name)\n",
    "        img = read_image(img_path)\n",
    "        \n",
    "        label = [1 if label_class is True else 0 for label_class in self.mapping[idx, 1:]]\n",
    "        label = np.array(label)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    def translate_encoded_label(self, encoded_label):\n",
    "        return self.classes_list[list(encoded_label).index(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59163\n"
     ]
    }
   ],
   "source": [
    "dataset = UNSW_NB15()\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.9 * len(dataset))\n",
    "val_split = int(0.8 * len(dataset))\n",
    "train, test = random_split(dataset, [train_split, len(dataset) - train_split])\n",
    "train, val = random_split(train, [val_split, len(train) - val_split])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47330\n",
      "5916\n",
      "5917\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([256, 3, 64, 128])\n",
      "Labels batch shape: torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([256, 3, 64, 128])\n",
      "Labels batch shape: torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "val_features, val_labels = next(iter(val_dataloader))\n",
    "print(f\"Feature batch shape: {val_features.size()}\")\n",
    "print(f\"Labels batch shape: {val_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([256, 3, 64, 128])\n",
      "Labels batch shape: torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "print(f\"Feature batch shape: {test_features.size()}\")\n",
    "print(f\"Labels batch shape: {test_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8888888888888888\n",
      "Recall: 0.8333333333333334\n",
      "F1 score: 0.8222222222222223\n"
     ]
    }
   ],
   "source": [
    "def precision_recall_f1(predictions, labels):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for x,y in zip(predictions, labels):\n",
    "        y_pred.append(x)\n",
    "        y_true.append(list(y).index(1.0))\n",
    "        \n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    return p, r, f1\n",
    "\n",
    "predictions = torch.Tensor(np.array([0, 1, 0, 0, 2]))\n",
    "labels = torch.Tensor(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1]]))\n",
    "p, r, f1 = precision_recall_f1(predictions, labels)\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvikioza\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\VScode Projects\\FIIT_MASTERS\\DP\\src\\models\\notebooks\\wandb\\run-20250102_122351-axpezrvv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vikioza/DP/runs/axpezrvv' target=\"_blank\">hopeful-paper-23</a></strong> to <a href='https://wandb.ai/vikioza/DP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vikioza/DP' target=\"_blank\">https://wandb.ai/vikioza/DP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vikioza/DP/runs/axpezrvv' target=\"_blank\">https://wandb.ai/vikioza/DP/runs/axpezrvv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:22<00:00,  1.42s/it]\n",
      "100%|██████████| 24/24 [00:20<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 1: 2.2603\n",
      "Valid Loss EPOCH 1: 2.2675\n",
      "Train Accuracy EPOCH 1: 0.2006\n",
      "Valid Accuracy EPOCH 1: 0.1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 10%|█         | 1/10 [04:48<43:15, 288.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.09178956281272484, Recall: 0.10035981624398438, F1 score: 0.03656591063884508\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:26<00:00,  1.44s/it]\n",
      "100%|██████████| 24/24 [00:20<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 2: 2.2612\n",
      "Valid Loss EPOCH 2: 2.2675\n",
      "Train Accuracy EPOCH 2: 0.1999\n",
      "Valid Accuracy EPOCH 2: 0.1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 20%|██        | 2/10 [09:39<38:42, 290.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.01999366152545954, Recall: 0.1, F1 score: 0.03332452943144402\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:29<00:00,  1.45s/it]\n",
      "100%|██████████| 24/24 [00:20<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 3: 2.2612\n",
      "Valid Loss EPOCH 3: 2.2635\n",
      "Train Accuracy EPOCH 3: 0.1999\n",
      "Valid Accuracy EPOCH 3: 0.1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 30%|███       | 3/10 [14:34<34:05, 292.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.01999366152545954, Recall: 0.1, F1 score: 0.03332452943144402\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:30<00:00,  1.46s/it]\n",
      "100%|██████████| 24/24 [00:20<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 4: 2.2123\n",
      "Valid Loss EPOCH 4: 2.1936\n",
      "Train Accuracy EPOCH 4: 0.2485\n",
      "Valid Accuracy EPOCH 4: 0.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 40%|████      | 4/10 [19:30<29:21, 293.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.07422852332178814, Recall: 0.13238479449656568, F1 score: 0.07629146268835962\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:32<00:00,  1.47s/it]\n",
      "100%|██████████| 24/24 [00:20<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 5: 2.1915\n",
      "Valid Loss EPOCH 5: 2.1916\n",
      "Train Accuracy EPOCH 5: 0.2696\n",
      "Valid Accuracy EPOCH 5: 0.2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 50%|█████     | 5/10 [24:27<24:35, 295.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.11431032183503816, Recall: 0.14529662827717088, F1 score: 0.09472593414386435\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:31<00:00,  1.47s/it]\n",
      "100%|██████████| 24/24 [00:20<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 6: 2.1924\n",
      "Valid Loss EPOCH 6: 2.2495\n",
      "Train Accuracy EPOCH 6: 0.2687\n",
      "Valid Accuracy EPOCH 6: 0.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 60%|██████    | 6/10 [29:25<19:43, 295.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.13941677215424225, Recall: 0.14440918201395309, F1 score: 0.09888016282971342\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:28<00:00,  1.45s/it]\n",
      "100%|██████████| 24/24 [00:19<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 7: 2.2128\n",
      "Valid Loss EPOCH 7: 2.2578\n",
      "Train Accuracy EPOCH 7: 0.2484\n",
      "Valid Accuracy EPOCH 7: 0.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 70%|███████   | 7/10 [34:18<14:44, 294.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.10745698194915317, Recall: 0.11999597466285312, F1 score: 0.07059473076881657\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:40<00:00,  1.52s/it]\n",
      "100%|██████████| 24/24 [00:23<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 8: 2.2526\n",
      "Valid Loss EPOCH 8: 2.2565\n",
      "Train Accuracy EPOCH 8: 0.2086\n",
      "Valid Accuracy EPOCH 8: 0.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 80%|████████  | 8/10 [39:27<09:58, 299.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.02085991971265582, Recall: 0.1, F1 score: 0.034519168575074734\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:40<00:00,  1.52s/it]\n",
      "100%|██████████| 24/24 [00:20<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 9: 2.2525\n",
      "Valid Loss EPOCH 9: 2.2525\n",
      "Train Accuracy EPOCH 9: 0.2086\n",
      "Valid Accuracy EPOCH 9: 0.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      " 90%|█████████ | 9/10 [44:33<05:01, 301.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.02085991971265582, Recall: 0.1, F1 score: 0.034519168575074734\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [04:26<00:00,  1.44s/it]\n",
      "100%|██████████| 24/24 [00:19<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 10: 2.2525\n",
      "Valid Loss EPOCH 10: 2.2565\n",
      "Train Accuracy EPOCH 10: 0.2086\n",
      "Valid Accuracy EPOCH 10: 0.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 10/10 [49:24<00:00, 296.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.02085991971265582, Recall: 0.1, F1 score: 0.034519168575074734\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), betas=ADAM_BETAS, lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY)\n",
    "\n",
    "run = wandb.init(\n",
    "    project = \"DP\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"architecture\": \"ViT\",\n",
    "        \"dataset\": \"UNSW-NB15-payload\",\n",
    "        \"epochs\": EPOCHS,\n",
    "    }\n",
    ")\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), position=0, leave=True):\n",
    "    model.train()\n",
    "    train_labels = []\n",
    "    train_preds = []\n",
    "    train_running_loss = 0\n",
    "    for idx, (img, label) in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        img = img.float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        y_pred = model(img)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        train_labels.extend(label.cpu().detach())\n",
    "        train_preds.extend(y_pred_label.cpu().detach())\n",
    "        \n",
    "        loss = criterion(y_pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    val_running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "            img = img.float().to(device)\n",
    "            label = label.float().to(device)         \n",
    "            y_pred = model(img)\n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "            \n",
    "            val_labels.extend(label.cpu().detach())\n",
    "            val_preds.extend(y_pred_label.cpu().detach())\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "            val_running_loss += loss.item()\n",
    "    val_loss = val_running_loss / (idx + 1)\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n",
    "    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "    train_accuracy = sum(1 for x,y in zip(train_preds, train_labels) if x == list(y).index(1.0)) / len(train_labels)\n",
    "    print(f\"Train Accuracy EPOCH {epoch+1}: {train_accuracy:.4f}\")\n",
    "    val_accuracy = sum(1 for x,y in zip(val_preds, val_labels) if x == list(y).index(1.0)) / len(val_labels)\n",
    "    print(f\"Valid Accuracy EPOCH {epoch+1}: {val_accuracy:.4f}\")\n",
    "    precision, recall, f1score = precision_recall_f1(train_preds, train_labels)\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1 score: {f1score}\")\n",
    "    print(\"-\"*30)\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_acc\": train_accuracy,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_acc\": val_accuracy,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1 score\": f1score\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>f1 score</td><td>▁▁▁▆██▅▁▁▁</td></tr><tr><td>precision</td><td>▅▁▁▄▇█▆▁▁▁</td></tr><tr><td>recall</td><td>▁▁▁▆██▄▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▆██▆▂▂▂</td></tr><tr><td>train_loss</td><td>███▃▁▁▃▇▇▇</td></tr><tr><td>val_acc</td><td>▁▁▁██▂▂▂▂▂</td></tr><tr><td>val_loss</td><td>███▁▁▆▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>f1 score</td><td>0.03452</td></tr><tr><td>precision</td><td>0.02086</td></tr><tr><td>recall</td><td>0.1</td></tr><tr><td>train_acc</td><td>0.2086</td></tr><tr><td>train_loss</td><td>2.25254</td></tr><tr><td>val_acc</td><td>0.20707</td></tr><tr><td>val_loss</td><td>2.25647</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-paper-23</strong> at: <a href='https://wandb.ai/vikioza/DP/runs/axpezrvv' target=\"_blank\">https://wandb.ai/vikioza/DP/runs/axpezrvv</a><br> View project at: <a href='https://wandb.ai/vikioza/DP' target=\"_blank\">https://wandb.ai/vikioza/DP</a><br>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250102_122351-axpezrvv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save as artifact for version control.\n",
    "# torch.save(model.state_dict(), '../saved/model_test_2')\n",
    "# artifact = wandb.Artifact('model_test_2', type='model')\n",
    "# artifact.add_file('../saved/model_test_2')\n",
    "# run.log_artifact(artifact)\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
