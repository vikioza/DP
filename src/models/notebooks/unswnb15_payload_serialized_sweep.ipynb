{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikio\\AppData\\Local\\Temp\\ipykernel_27576\\2052541112.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "# Input params\n",
    "HEIGHT = 64\n",
    "WIDTH = 128\n",
    "IN_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Embedding params\n",
    "PATCH_SIZE = 16\n",
    "EMBED_DIM = (PATCH_SIZE ** 2) * IN_CHANNELS\n",
    "NUM_PATCHES = (HEIGHT // PATCH_SIZE) * (WIDTH // PATCH_SIZE)\n",
    "DROPOUT = 0.01\n",
    "\n",
    "# Model params\n",
    "NUM_HEADS = 8\n",
    "NUM_ENCODERS = 4\n",
    "ACTIVATION=\"gelu\"\n",
    "\n",
    "# Optim params\n",
    "ADAM_BETAS = (0.9, 0.999)\n",
    "ADAM_WEIGHT_DECAY = 0\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "# Train loop params\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, patch_size, num_patches, dropout, in_channels):\n",
    "        super().__init__()\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "            ),\n",
    "            nn.Flatten(2))\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(size=(1, in_channels, embed_dim)), requires_grad=True)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(size=(1, num_patches+in_channels, embed_dim)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "\n",
    "        x = self.patcher(x).permute(0, 2, 1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        x = self.position_embeddings + x\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 35, 768])\n"
     ]
    }
   ],
   "source": [
    "model = PatchEmbedding(EMBED_DIM, PATCH_SIZE, NUM_PATCHES, DROPOUT, IN_CHANNELS).to(device)\n",
    "x = torch.randn(BATCH_SIZE, IN_CHANNELS, HEIGHT, WIDTH).to(device)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_patches, num_classes, patch_size, embed_dim, num_encoders, num_heads, dropout, activation, in_channels):\n",
    "        super().__init__()\n",
    "        self.embeddings_block = PatchEmbedding(embed_dim, patch_size, num_patches, dropout, in_channels)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True)\n",
    "        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim),\n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings_block(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.mlp_head(x[:, 0, :])  # Apply MLP on the CLS token only\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikio\\anaconda3\\envs\\DP\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "model = ViT(NUM_PATCHES, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, DROPOUT, ACTIVATION, IN_CHANNELS).to(device)\n",
    "x = torch.randn(BATCH_SIZE, IN_CHANNELS, HEIGHT, WIDTH).to(device)\n",
    "print(model(x).shape) # BATCH_SIZE X NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (embeddings_block): PatchEmbedding(\n",
       "    (patcher): Sequential(\n",
       "      (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (1): Flatten(start_dim=2, end_dim=-1)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.01, inplace=False)\n",
       "  )\n",
       "  (encoder_blocks): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.01, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.01, inplace=False)\n",
       "        (dropout2): Dropout(p=0.01, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=768, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNSW_NB15(Dataset):\n",
    "    BASE_PATH = \"C:\\VScode Projects\\FIIT_MASTERS\\DP\\datasets\\\\UNSW_NB15\"\n",
    "    MAPPING_FILE = \"\\\\unswnb15_img_serialized_5_non_shuffled.csv\"\n",
    "    FOLDER = \"\\image_serialized_5_non_shuffled\"\n",
    "    index: int\n",
    "    batch_size: int\n",
    "    classes_count: int\n",
    "    classes_list: list\n",
    "    \n",
    "    def __init__(self, shuffle: bool = False):        \n",
    "        self.mapping = pd.read_csv(self.BASE_PATH+self.MAPPING_FILE)\n",
    "        self.mapping = pd.get_dummies(self.mapping, columns=['label'])\n",
    "        \n",
    "        if shuffle:\n",
    "            self.mapping = self.mapping.sample(frac=1) # shuffle\n",
    "            \n",
    "        self.classes_list = [label.split(\"_\")[1] for label in self.mapping.columns[1:]]\n",
    "        \n",
    "        self.mapping = self.mapping.to_numpy()\n",
    "        \n",
    "        self.classes_count = len(self.mapping[0]) - 1\n",
    "        \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()]) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mapping)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.mapping[idx, 0]\n",
    "        img_path = os.path.join(self.BASE_PATH + self.FOLDER, img_name)\n",
    "        img = read_image(img_path)\n",
    "        \n",
    "        label = [1 if label_class is True else 0 for label_class in self.mapping[idx, 1:]]\n",
    "        label = np.array(label)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    def translate_encoded_label(self, encoded_label):\n",
    "        return self.classes_list[list(encoded_label).index(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59163\n"
     ]
    }
   ],
   "source": [
    "dataset = UNSW_NB15()\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.9 * len(dataset))\n",
    "val_split = int(0.8 * len(dataset))\n",
    "train, test = random_split(dataset, [train_split, len(dataset) - train_split])\n",
    "train, val = random_split(train, [val_split, len(train) - val_split])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47330\n",
      "5916\n",
      "5917\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([512, 3, 64, 128])\n",
      "Labels batch shape: torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([512, 3, 64, 128])\n",
      "Labels batch shape: torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "val_features, val_labels = next(iter(val_dataloader))\n",
    "print(f\"Feature batch shape: {val_features.size()}\")\n",
    "print(f\"Labels batch shape: {val_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([512, 3, 64, 128])\n",
      "Labels batch shape: torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "print(f\"Feature batch shape: {test_features.size()}\")\n",
    "print(f\"Labels batch shape: {test_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8888888888888888\n",
      "Recall: 0.8333333333333334\n",
      "F1 score: 0.8222222222222223\n"
     ]
    }
   ],
   "source": [
    "def precision_recall_f1(predictions, labels):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for x,y in zip(predictions, labels):\n",
    "        y_pred.append(x)\n",
    "        y_true.append(list(y).index(1.0))\n",
    "        \n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    return p, r, f1\n",
    "\n",
    "predictions = torch.Tensor(np.array([0, 1, 0, 0, 2]))\n",
    "labels = torch.Tensor(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1]]))\n",
    "p, r, f1 = precision_recall_f1(predictions, labels)\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"Recall: {r}\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Concatenate, Optional, ParamSpec, TypeVar, Dict\n",
    "from functools import wraps\n",
    "\n",
    "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "P = ParamSpec(\"P\")\n",
    "A = TypeVar(\"A\")\n",
    "B = TypeVar(\"B\")\n",
    "\n",
    "def wandb_init(config_: Dict[str, str]):\n",
    "    def wandb_init_(func: Callable[Concatenate[A, P], B]):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args: P.args, **kwargs: P.kwargs) -> Optional[Any]:\n",
    "            wandb.init(project=config_['project_name'] if config_ is not None else None, config=config_, dir=CURRENT_DIR)\n",
    "            result = func(*args, **kwargs)\n",
    "            wandb.finish()\n",
    "\n",
    "            return result\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return wandb_init_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvikioza\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\VScode Projects\\FIIT_MASTERS\\DP\\src\\models\\notebooks\\wandb\\run-20250101_202240-l9nv5hdp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vikioza/DP/runs/l9nv5hdp' target=\"_blank\">glorious-totem-18</a></strong> to <a href='https://wandb.ai/vikioza/DP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vikioza/DP' target=\"_blank\">https://wandb.ai/vikioza/DP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vikioza/DP/runs/l9nv5hdp' target=\"_blank\">https://wandb.ai/vikioza/DP/runs/l9nv5hdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 52/93 [00:27<00:21,  1.93it/s]"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), betas=ADAM_BETAS, lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY)\n",
    "\n",
    "run = wandb.init(\n",
    "    project = \"DP\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"architecture\": \"ViT\",\n",
    "        \"dataset\": \"UNSW-NB15-payload\",\n",
    "        \"epochs\": EPOCHS,\n",
    "    }\n",
    ")\n",
    "\n",
    "def fit():\n",
    "    def train_loop():\n",
    "        model.train()\n",
    "        train_labels = []\n",
    "        train_preds = []\n",
    "        train_running_loss = 0\n",
    "        for idx, (img, label) in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "            img = img.float().to(device)\n",
    "            label = label.float().to(device)\n",
    "            y_pred = model(img)\n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "            train_labels.extend(label.cpu().detach())\n",
    "            train_preds.extend(y_pred_label.cpu().detach())\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += loss.item()\n",
    "        return train_running_loss / (idx + 1), train_labels, train_preds\n",
    "        \n",
    "    def valid():\n",
    "        model.eval()\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "        val_running_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for idx, (img, label) in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "                img = img.float().to(device)\n",
    "                label = label.float().to(device)         \n",
    "                y_pred = model(img)\n",
    "                y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "                \n",
    "                val_labels.extend(label.cpu().detach())\n",
    "                val_preds.extend(y_pred_label.cpu().detach())\n",
    "                \n",
    "                loss = criterion(y_pred, label)\n",
    "                val_running_loss += loss.item()\n",
    "        return val_running_loss / (idx + 1), val_labels, val_preds\n",
    "        \n",
    "    for epoch in tqdm(range(EPOCHS), position=0, leave=True):\n",
    "        train_loss, train_labels, train_preds = train_loop()\n",
    "        val_loss, val_labels, val_preds = valid()\n",
    "        \n",
    "        print(\"-\"*30)\n",
    "        print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n",
    "        print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "        train_accuracy = sum(1 for x,y in zip(train_preds, train_labels) if x == list(y).index(1.0)) / len(train_labels)\n",
    "        print(f\"Train Accuracy EPOCH {epoch+1}: {train_accuracy:.4f}\")\n",
    "        val_accuracy = sum(1 for x,y in zip(val_preds, val_labels) if x == list(y).index(1.0)) / len(val_labels)\n",
    "        print(f\"Valid Accuracy EPOCH {epoch+1}: {val_accuracy:.4f}\")\n",
    "        precision, recall, f1score = precision_recall_f1(train_preds, train_labels)\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1 score: {f1score}\")\n",
    "        print(\"-\"*30)\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_acc\": train_accuracy,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_acc\": val_accuracy,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1 score\": f1score\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>f1 score</td><td>█▇▇▇▆▆▅▅▄▄▃▃▂▃▃▃▂▄▁▃▃▂▃▄▃▃▂▅▄▃</td></tr><tr><td>precision</td><td>▇▆▅█▇▄▄▄▄▄▁▄▄▁▃▁▁▄▅▄▆▁▄▄▄▃▁▇▄▃</td></tr><tr><td>recall</td><td>▂▂▃█▄▄▃▆▄▆▄▁▄▁▄▄▄▄▃▁▁▅▄▂▃▃▂▃▃▃</td></tr><tr><td>train_acc</td><td>▁▄▅▇▆▆▆█▇██▆█▆▇▇█▇█▆▆█▇▇▇▇▇▆▇▇</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▆▁██▁█▆██▆█▆▆▆██▇▆███▇▆█▆▇█▇▆▆</td></tr><tr><td>val_loss</td><td>█▂▆▃▆▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁▂▂▁▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>29</td></tr><tr><td>f1 score</td><td>0.07211</td></tr><tr><td>precision</td><td>0.07348</td></tr><tr><td>recall</td><td>0.10013</td></tr><tr><td>train_acc</td><td>0.20687</td></tr><tr><td>train_loss</td><td>1.85813</td></tr><tr><td>val_acc</td><td>0.20521</td></tr><tr><td>val_loss</td><td>1.85565</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-water-17</strong> at: <a href='https://wandb.ai/vikioza/DP/runs/40noi4q4' target=\"_blank\">https://wandb.ai/vikioza/DP/runs/40noi4q4</a><br> View project at: <a href='https://wandb.ai/vikioza/DP' target=\"_blank\">https://wandb.ai/vikioza/DP</a><br>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250101_185413-40noi4q4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save as artifact for version control.\n",
    "torch.save(model.state_dict(), 'saved/model_test_2')\n",
    "artifact = wandb.Artifact('model_test_2', type='model')\n",
    "artifact.add_file('saved/model_test_2')\n",
    "run.log_artifact(artifact)\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
