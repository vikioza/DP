{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import timeit\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from model_definition import ViT\n",
    "from dataset_definition import CicIds2017\n",
    "from model_utils import precision_recall_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = True\n",
    "MODEL_NAME = \"model_cic_payload_bin_serial_bi_dir_exp_4\"\n",
    "\n",
    "EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "PATCH_SIZE = 8\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "IN_CHANNELS = 3\n",
    "NUM_HEADS = 16\n",
    "DROPOUT = 0.1\n",
    "ADAM_WEIGHT_DECAY = 0\n",
    "ADAM_BETAS = (0.9, 0.999)\n",
    "ACTIVATION=\"gelu\"\n",
    "NUM_ENCODERS = 24\n",
    "EMBED_DIM = (PATCH_SIZE ** 2) * IN_CHANNELS # (8**2)*3=192\n",
    "NUM_PATCHES = (HEIGHT // PATCH_SIZE) * (WIDTH // PATCH_SIZE) # 4*8=32\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(NUM_PATCHES, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, DROPOUT, ACTIVATION, IN_CHANNELS).to(device)\n",
    "x = torch.randn(BATCH_SIZE, IN_CHANNELS, HEIGHT, WIDTH).to(device)\n",
    "print(model(x).shape) # BATCH_SIZE X NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CicIds2017(mapping_file_name=\"clean\\cicids2017_img_bi_dir_selection.csv\", image_folder_name=\"clean\\image_bi_dir\", binary=True, hdf5=True)\n",
    "print(len(dataset), len(dataset.classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = int(0.9 * len(dataset))\n",
    "train, val = random_split(dataset, [val_split, len(dataset) - val_split])\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), betas=ADAM_BETAS, lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY)\n",
    "\n",
    "if CHECKPOINT:\n",
    "    checkpoint = torch.load(\"saved/\" + MODEL_NAME)\n",
    "    starting_epoch = checkpoint.get(\"epoch\")\n",
    "    run_id = checkpoint.get(\"run_id\")\n",
    "    model.load_state_dict(checkpoint.get(\"model_state\"))\n",
    "    optimizer.load_state_dict(checkpoint.get(\"optimizer_state\"))\n",
    "else:\n",
    "    starting_epoch = 0\n",
    "    run_id = wandb.util.generate_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project = \"DP\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"architecture\": \"ViT\",\n",
    "        \"dataset\": \"CIC-IDS-2017-payload-exp-new\",\n",
    "        \"epochs\": EPOCHS,\n",
    "    },\n",
    "    id=run_id,\n",
    "    resume=\"allow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "for epoch in tqdm(range(starting_epoch, starting_epoch+EPOCHS), position=0, leave=True):\n",
    "    model.train()\n",
    "    train_labels = []\n",
    "    train_preds = []\n",
    "    train_running_loss = 0\n",
    "    for idx, (img, label) in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        img = img.float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        y_pred = model(img)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        train_labels.extend(label.cpu().detach())\n",
    "        train_preds.extend(y_pred_label.cpu().detach())\n",
    "        \n",
    "        loss = criterion(y_pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    val_running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "            img = img.float().to(device)\n",
    "            label = label.float().to(device)         \n",
    "            y_pred = model(img)\n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "            \n",
    "            val_labels.extend(label.cpu().detach())\n",
    "            val_preds.extend(y_pred_label.cpu().detach())\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "            val_running_loss += loss.item()\n",
    "    val_loss = val_running_loss / (idx + 1)\n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n",
    "    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "    train_accuracy = sum(1 for x,y in zip(train_preds, train_labels) if x == list(y).index(1.0)) / len(train_labels)\n",
    "    print(f\"Train Accuracy EPOCH {epoch+1}: {train_accuracy:.4f}\")\n",
    "    val_accuracy = sum(1 for x,y in zip(val_preds, val_labels) if x == list(y).index(1.0)) / len(val_labels)\n",
    "    print(f\"Valid Accuracy EPOCH {epoch+1}: {val_accuracy:.4f}\")\n",
    "    precision, recall, f1score = precision_recall_f1(train_preds, train_labels)\n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1 score: {f1score}\")\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": starting_epoch+EPOCHS,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"run_id\": run_id,        \n",
    "        },\n",
    "        \"saved/\" + MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    wandb.log(\n",
    "        { \n",
    "            \"epoch\": epoch,\n",
    "            \"train_acc\": train_accuracy,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_acc\": val_accuracy,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1 score\": f1score\n",
    "        }\n",
    "    )\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(f\"Training Time: {stop-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "val_preds = []\n",
    "with torch.no_grad():\n",
    "    for idx, (img, label) in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "        img = img.float().to(device)\n",
    "        label = label.float().to(device)         \n",
    "        y_pred = model(img)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "        \n",
    "        val_labels.extend(label.cpu().detach())\n",
    "        val_preds.extend(y_pred_label.cpu().detach())\n",
    "\n",
    "test_accuracy = sum(1 for x,y in zip(val_preds, val_labels) if x == list(y).index(1.0)) / len(val_labels)\n",
    "print(f\"Val Accuracy: {test_accuracy:.4f}\")\n",
    "t_precision, t_recall, t_f1score = precision_recall_f1(val_preds, val_labels)\n",
    "print(f\"Precision: {t_precision}, Recall: {t_recall}, F1 score: {t_f1score}\")\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = wandb.Artifact(MODEL_NAME, type='model')\n",
    "artifact.add_file(\"saved/\" + MODEL_NAME)\n",
    "run.log_artifact(artifact)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix([list(y).index(1.0) for y in val_labels], val_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Anomaly\", \"Normal\"])\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp.plot(cmap=\"Blues\", ax=ax)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = ViT(NUM_PATCHES, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, DROPOUT, ACTIVATION, IN_CHANNELS)\n",
    "checkpoint = torch.load(\"best/\" + MODEL_NAME)\n",
    "saved_model.load_state_dict(checkpoint.get(\"model_state\"))\n",
    "# saved_model.load_state_dict(torch.load(\"best/\" + \"model_cic_payload_bin_serial_bi_dir_exp_2\"))\n",
    "saved_model.to(device)\n",
    "saved_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "val_preds = []\n",
    "with torch.no_grad():\n",
    "    for idx, (img, label) in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "        img = img.float().to(device)\n",
    "        label = label.float().to(device)         \n",
    "        y_pred = saved_model(img)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "        \n",
    "        val_labels.extend(label.cpu().detach())\n",
    "        val_preds.extend(y_pred_label.cpu().detach())\n",
    "\n",
    "test_accuracy = sum(1 for x,y in zip(val_preds, val_labels) if x == list(y).index(1.0)) / len(val_labels)\n",
    "print(f\"Val Accuracy: {test_accuracy:.4f}\")\n",
    "t_precision, t_recall, t_f1score = precision_recall_f1(val_preds, val_labels)\n",
    "print(f\"Precision: {t_precision}, Recall: {t_recall}, F1 score: {t_f1score}\")\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix([list(y).index(1.0) for y in val_labels], val_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Anomaly\", \"Normal\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = ViT(NUM_PATCHES, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, DROPOUT, ACTIVATION, IN_CHANNELS)\n",
    "checkpoint = torch.load(\"saved/\" + MODEL_NAME)\n",
    "saved_model.load_state_dict(checkpoint.get(\"model_state\"))\n",
    "# saved_model.load_state_dict(torch.load(\"best/\" + \"model_cic_payload_bin_serial_bi_dir_exp_2\"))\n",
    "saved_model.to(device)\n",
    "saved_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CicIds2017(binary=True, image_folder_name=\"clean\\image_bi_dir\", mapping_file_name=\"clean\\cicids2017_img_bi_dir_new_attacks.csv\", hdf5=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for idx, (img, label) in enumerate(tqdm(test_dataloader, position=0, leave=True)):\n",
    "        img = img.float().to(device)\n",
    "        label = label.float().to(device)         \n",
    "        y_pred = saved_model(img)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "        \n",
    "        test_labels.extend(label.cpu().detach())\n",
    "        test_preds.extend(y_pred_label.cpu().detach())\n",
    "\n",
    "test_accuracy = sum(1 for x,y in zip(test_preds, test_labels) if x == list(y).index(1.0)) / len(test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "t_precision, t_recall, t_f1score = precision_recall_f1(test_preds, test_labels)\n",
    "print(f\"Precision: {t_precision}, Recall: {t_recall}, F1 score: {t_f1score}\")\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix([list(y).index(1.0) for y in test_labels], test_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Anomaly\", \"Normal\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
