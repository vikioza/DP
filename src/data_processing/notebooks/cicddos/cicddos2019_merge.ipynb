{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Get the directory where the current script is located\n",
    "current_dir = os.path.dirname(os.getcwd()).split('\\\\')\n",
    "\n",
    "# Construct the path to your target folder (e.g., 'data' inside the repo)\n",
    "target_folder = \"/\".join(current_dir[:current_dir.index('src')+1])\n",
    "sys.path.append(os.path.abspath(target_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DIR = \"C:\\VScode_Projects\\DP\\datasets\\CIC-DDoS-2019\\\\raw\\csv\\\\03-11\"\n",
    "COLS = [\n",
    "    \"Flow ID\",\n",
    "    \" Source IP\",\n",
    "    \" Source Port\",\n",
    "    \" Destination IP\",\n",
    "    \" Destination Port\",\n",
    "    \" Protocol\",\n",
    "    \" Timestamp\",\n",
    "    \" Flow Duration\",\n",
    "    \" Label\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(dir: str, cols: list = None):\n",
    "    print(\"READING CSV FILES...\")\n",
    "\n",
    "    extension = \"*.csv\"\n",
    "    files = glob.glob(f\"{dir}/{extension}\")\n",
    "\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        print(f\"READING {file}\")\n",
    "        if cols:\n",
    "            dfs.append(pd.read_csv(file, usecols=cols))\n",
    "        else:\n",
    "            dfs.append(pd.read_csv(file))\n",
    "\n",
    "    print(\"MERGING CSV FILES...\")\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    print('DROPPING ROWS WITH MISSING \"Flow ID\"...')\n",
    "    df = df.drop(df[pd.isnull(df[\"Flow ID\"])].index)\n",
    "\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "    min_timestamp = df[\"Timestamp\"].min()\n",
    "\n",
    "    return df, min_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = read_csv(CSV_DIR, COLS)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Timestamp\": \"stime\", \"Flow Duration\": \"dur\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stime\"] = df[\"stime\"].apply(lambda x: x.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV = \"C:\\VScode_Projects\\DP\\datasets\\CIC-DDoS-2019\\clean\\labeled_sample.csv\"\n",
    "\n",
    "TARGET_UDP = 100000\n",
    "TARGET_LAG = 100000\n",
    "TARGET_BENIGN = 100000\n",
    "\n",
    "# Initialize counters\n",
    "udp_count = 0\n",
    "lag_count = 0\n",
    "benign_count = 0\n",
    "\n",
    "counter = 0\n",
    "for chunk in pd.read_csv(\"C:\\VScode_Projects\\DP\\datasets\\CIC-DDoS-2019\\clean\\sample.csv\", chunksize=100_000):\n",
    "    temp1 = pd.merge(chunk, df, how=\"left\", left_on=[\"src_ip\", \"src_p\", \"dst_ip\", \"dst_p\", \"protocol.1\",], right_on=[\"Source IP\", \"Source Port\", \"Destination IP\", \"Destination Port\", \"Protocol\"])\n",
    "    temp2 = pd.merge(chunk, df, how=\"left\", left_on=[\"src_ip\", \"src_p\", \"dst_ip\", \"dst_p\", \"protocol.1\",], right_on=[\"Destination IP\", \"Destination Port\", \"Source IP\", \"Source Port\", \"Protocol\"])\n",
    "    combine = pd.concat([temp1, temp2])\n",
    "    combine.drop_duplicates(inplace=True)\n",
    "    combine = combine[\n",
    "        (combine[\"stime\"] <= combine[\"timestamp\"])\n",
    "        & (combine[\"timestamp\"] <= combine[\"stime\"] + combine[\"dur\"])\n",
    "    ]\n",
    "    combine = combine.drop(columns=[\"stime\", \"dur\", \"timestamp\", \"Flow ID\", \"protocol.1\", \"Source IP\", \"Source Port\", \"Destination IP\", \"Destination Port\", \"Protocol\"])\n",
    "    chunk = combine.rename(columns={\"Label\": \"label\"})\n",
    "    \n",
    "    # Initialize output file with header\n",
    "    if counter == 0:\n",
    "        columns = chunk.columns\n",
    "        pd.DataFrame(columns=columns).to_csv(OUTPUT_CSV, mode='w', index=False)\n",
    "    counter += 1\n",
    "    \n",
    "    # Split into categories\n",
    "    udp_mask = chunk['label'] == 'UDP'\n",
    "    lag_mask = chunk['label'] == 'UDPLag'\n",
    "    benign_mask = chunk['label'] == 'BENIGN'\n",
    "    other_mask = ~(udp_mask | benign_mask)\n",
    "    \n",
    "    # Handle UDP rows\n",
    "    if udp_count < TARGET_UDP:\n",
    "        udp_chunk = chunk[udp_mask]\n",
    "        needed = TARGET_UDP - udp_count\n",
    "        udp_samples = udp_chunk.head(needed)\n",
    "        udp_samples.to_csv(OUTPUT_CSV, mode='a', header=False, index=False)\n",
    "        udp_count += len(udp_samples)\n",
    "        \n",
    "    # Handle LAG rows\n",
    "    if lag_count < TARGET_LAG:\n",
    "        lag_chunk = chunk[lag_mask]\n",
    "        needed = TARGET_LAG - lag_count\n",
    "        lag_samples = lag_chunk.head(needed)\n",
    "        lag_samples.to_csv(OUTPUT_CSV, mode='a', header=False, index=False)\n",
    "        lag_count += len(lag_samples)\n",
    "    \n",
    "    # Handle BENIGN rows\n",
    "    if benign_count < TARGET_BENIGN:\n",
    "        benign_chunk = chunk[benign_mask]\n",
    "        needed = TARGET_BENIGN - benign_count\n",
    "        benign_samples = benign_chunk.head(needed)\n",
    "        benign_samples.to_csv(OUTPUT_CSV, mode='a', header=False, index=False)\n",
    "        benign_count += len(benign_samples)\n",
    "    \n",
    "    # Handle other rows\n",
    "    chunk[other_mask].to_csv(OUTPUT_CSV, mode='a', header=False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.read_csv(\"C:\\VScode_Projects\\DP\\datasets\\CIC-DDoS-2019\\clean\\labeled_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check.label.value_counts()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
